{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "10-4. Linear_Regression_pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_8T41-9zbSZ"
      },
      "source": [
        "# Multi-Variable Linear Regression Example with Pytorch Models (다중 변수의 선형회귀)\n",
        "- 국립한밭대학교 컴퓨터공학과 임경태\n",
        "- https://sites.google.com/view/aailab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lIpE4w9zZk1"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mca1SNfEzZiX"
      },
      "source": [
        "x_train = np.array([[2, 3, 1], \n",
        "                    [4, 8, 9], \n",
        "                    [6, 2, 7], \n",
        "                    [8, 4, 6]])\n",
        "y_train = np.array([[3], \n",
        "                    [7], \n",
        "                    [5], \n",
        "                    [8]])\n",
        "\n",
        "n_samples = x_train.shape[0]\n",
        "n_features = x_train.shape[1]\n",
        "losses = []"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbTXHxpRzZfx"
      },
      "source": [
        "import torch"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "torch.nn.Linear \\_\\_init\\_\\_()\n",
        "\n",
        "```\n",
        "    def __init__(self, in1_features: int, in2_features: int, out_features: int, bias: bool = True,\n",
        "                 device=None, dtype=None) -> None:\n",
        "        factory_kwargs = {'device': device, 'dtype': dtype}\n",
        "        super(Bilinear, self).__init__()\n",
        "        self.in1_features = in1_features\n",
        "        self.in2_features = in2_features\n",
        "        self.out_features = out_features\n",
        "        self.weight = Parameter(torch.empty((out_features, in1_features, in2_features), **factory_kwargs))\n",
        "\n",
        "        if bias:\n",
        "            self.bias = Parameter(torch.empty(out_features, **factory_kwargs))\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "        self.reset_parameters()\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "6YrTrP1R04zT"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEt9NHcPzZdL",
        "outputId": "3de1a7fb-fa2d-49ee-f262-2d7191ec7844"
      },
      "source": [
        "linear_model = torch.nn.Linear(in_features=3, out_features=1)\n",
        "\n",
        "print(linear_model)\n",
        "print(list(linear_model.parameters()))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear(in_features=3, out_features=1, bias=True)\n",
            "[Parameter containing:\n",
            "tensor([[0.5546, 0.4457, 0.2460]], requires_grad=True), Parameter containing:\n",
            "tensor([0.1530], requires_grad=True)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QOMPQVNzZae",
        "outputId": "55d49a41-d4ca-4ee6-a23e-4356e4a7417d"
      },
      "source": [
        "x_train_torch = torch.from_numpy(x_train).float()\n",
        "y_train_torch = torch.from_numpy(y_train).float()\n",
        "print(x_train_torch)\n",
        "print(x_train_torch.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[2., 3., 1.],\n",
            "        [4., 8., 9.],\n",
            "        [6., 2., 7.],\n",
            "        [8., 4., 6.]])\n",
            "torch.Size([4, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlKg4h-jzZX_"
      },
      "source": [
        "predicted_y = linear_model(x_train_torch)  # forward 함수 실행"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "torch.nn.Linear forward()\n",
        "```\n",
        "    def forward(self, input: Tensor) -> Tensor:\n",
        "        return F.linear(input, self.weight, self.bias)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "YpyTSA8P3rMg"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kt525ZDzZVl"
      },
      "source": [
        "optimizer = torch.optim.SGD(linear_model.parameters(), lr=0.01)  # 업데이트할 파라미터를 지정(linear_model.parameters())\n",
        "loss_function = torch.nn.MSELoss()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHniQjJmzZSu",
        "outputId": "23bc2280-9697-49aa-82af-60ef88f222aa"
      },
      "source": [
        "linear_model.train()\n",
        "for idx in range(100):\n",
        "  optimizer.zero_grad()\n",
        "  predicted_y = linear_model(x_train_torch)\n",
        "  loss = loss_function(predicted_y, y_train_torch)  \n",
        "  print(loss.item())\n",
        "  loss.backward()\n",
        "  optimizer.step()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6425564289093018\n",
            "0.47648561000823975\n",
            "0.37229034304618835\n",
            "0.30499011278152466\n",
            "0.2598814368247986\n",
            "0.22828640043735504\n",
            "0.20506255328655243\n",
            "0.18714553117752075\n",
            "0.17269760370254517\n",
            "0.16060250997543335\n",
            "0.15017428994178772\n",
            "0.14098221063613892\n",
            "0.1327490210533142\n",
            "0.12529124319553375\n",
            "0.11848177015781403\n",
            "0.11222980916500092\n",
            "0.10646726191043854\n",
            "0.10114097595214844\n",
            "0.09620796144008636\n",
            "0.09163199365139008\n",
            "0.08738227933645248\n",
            "0.08343236893415451\n",
            "0.07975813746452332\n",
            "0.07633823156356812\n",
            "0.07315360754728317\n",
            "0.0701865702867508\n",
            "0.06742135435342789\n",
            "0.06484293937683105\n",
            "0.06243814900517464\n",
            "0.06019458919763565\n",
            "0.05810059607028961\n",
            "0.05614569038152695\n",
            "0.05432021990418434\n",
            "0.05261501669883728\n",
            "0.05102146416902542\n",
            "0.04953200742602348\n",
            "0.048139262944459915\n",
            "0.04683660715818405\n",
            "0.045617781579494476\n",
            "0.04447680711746216\n",
            "0.04340840131044388\n",
            "0.04240765422582626\n",
            "0.0414697527885437\n",
            "0.040590282529592514\n",
            "0.03976532071828842\n",
            "0.038991160690784454\n",
            "0.038264110684394836\n",
            "0.037581223994493484\n",
            "0.036939170211553574\n",
            "0.036335401237010956\n",
            "0.03576691821217537\n",
            "0.03523164615035057\n",
            "0.03472721576690674\n",
            "0.0342513844370842\n",
            "0.033802397549152374\n",
            "0.03337819129228592\n",
            "0.03297719359397888\n",
            "0.03259778767824173\n",
            "0.032238539308309555\n",
            "0.03189803287386894\n",
            "0.03157506138086319\n",
            "0.031268294900655746\n",
            "0.030976776033639908\n",
            "0.030699368566274643\n",
            "0.03043510392308235\n",
            "0.030183162540197372\n",
            "0.029942795634269714\n",
            "0.029712967574596405\n",
            "0.029493100941181183\n",
            "0.029282648116350174\n",
            "0.02908078394830227\n",
            "0.028887035325169563\n",
            "0.028700824826955795\n",
            "0.028521614149212837\n",
            "0.02834903821349144\n",
            "0.028182657435536385\n",
            "0.0280219167470932\n",
            "0.027866538614034653\n",
            "0.027716245502233505\n",
            "0.027570582926273346\n",
            "0.027429234236478806\n",
            "0.027291934937238693\n",
            "0.027158662676811218\n",
            "0.02702874131500721\n",
            "0.026902351528406143\n",
            "0.02677890658378601\n",
            "0.026658598333597183\n",
            "0.02654092013835907\n",
            "0.026425840333104134\n",
            "0.026313111186027527\n",
            "0.026202723383903503\n",
            "0.026094526052474976\n",
            "0.025988120585680008\n",
            "0.02588381990790367\n",
            "0.02578115463256836\n",
            "0.02568015083670616\n",
            "0.025580769404768944\n",
            "0.025482794269919395\n",
            "0.025386318564414978\n",
            "0.02529103308916092\n"
          ]
        }
      ]
    }
  ]
}